{"timestamp": 1698744674.282795, "stored_source_code": "# add default values for parameters here\n# QAOA and QAA to solve a QUBO problem\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pulser import Pulse, Sequence, Register\nfrom pulser_simulation import QutipEmulator\nfrom pulser.devices import Chadoq2\nfrom pulser.waveforms import InterpolatedWaveform\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\n## 1. Introduction \nIn this tutorial, we illustrate how to solve a Quadratic Unconstrained Binary Optimization (QUBO) instance using an ensemble of Rydberg atoms in analog mode.\n\nQUBO has been extensively studied [Glover, et al., 2018](https://arxiv.org/pdf/1811.11538.pdf) and is used to model and solve numerous categories of optimization problems including important instances of network flows, scheduling, max-cut, max-clique, vertex cover and other graph and management science problems, integrating them into a unified modeling framework.\n\nMathematically, a QUBO instance consists of a symmetric matrix $Q$ of size $(N \\times N)$, and the optimization problem associated with it is to find the bitstring $z=(z_1, \\dots, z_N) \\in \\{0, 1 \\}^N$ that minimizes the quantity\n$$f(z) = z^{T}Qz$$ \n\n\nIn this tutorial, we will demonstrate how a QUBO instance can be mapped and solved using neutral atoms.\nSuppose we are given the following QUBO matrix $Q$:\nQ = np.array(\n    [\n        [-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n        [19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n        [19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n        [5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n        [5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n    ]\n)\nBecause the QUBO is small, we can classically check all solutions and mark the optimal ones. This will help us later in the tutorial to visualize the quality of our quantum approach.\nbitstrings = [np.binary_repr(i, len(Q)) for i in range(2 ** len(Q))]\ncosts = []\n# this takes exponential time with the dimension of the QUBO\nfor b in bitstrings:\n    z = np.array(list(b), dtype=int)\n    cost = z.T @ Q @ z\n    costs.append(cost)\nzipped = zip(bitstrings, costs)\nsort_zipped = sorted(zipped, key=lambda x: x[1])\nprint(sort_zipped[:3])\nThis QUBO admits `01011` and `00111` as optimal solutions.\n### Embedding a QUBO onto an atomic register\nWe now illustrate how to use Pulser to embbed the QUBO matrix $Q$ on a neutral-atom device.\n\nThe key idea is to encode the off-diagonal terms of $Q$ by using the Rydberg interaction between atoms. As the interaction $U$ depends on the pairwise distance ($U=C_6/r_{ij}^6$) between atoms $i$ and $j$, we attempt to find the optimal positions of the atoms in the Register that replicate best the off-diagonal terms of $Q$:\ndef evaluate_mapping(new_coords, *args):\n    \"\"\"Cost function to minimize. Ideally, the pairwise\n    distances are conserved\"\"\"\n    Q, shape = args\n    new_coords = np.reshape(new_coords, shape)\n    new_Q = squareform(Chadoq2.interaction_coeff / pdist(new_coords) ** 6)\n    return np.linalg.norm(new_Q - Q)\nshape = (len(Q), 2)\ncosts = []\nnp.random.seed(0)\nx0 = np.random.random(shape).flatten()\nres = minimize(\n    evaluate_mapping,\n    x0,\n    args=(Q, shape),\n    method=\"Nelder-Mead\",\n    tol=1e-6,\n    options={\"maxiter\": 200000, \"maxfev\": None},\n)\ncoords = np.reshape(res.x, (len(Q), 2))\nWe can then plot the obtained coordinates in a Register using:\nqubits = dict(enumerate(coords))\nreg = Register(qubits)\nreg.draw(\n    blockade_radius=Chadoq2.rydberg_blockade_radius(1.0),\n    draw_graph=False,\n    draw_half_radius=True,\n)\n## 2. Building the quantum algorithm \nNow that the QUBO $Q$ is encoded in the Register, we can peprare the following Ising Hamiltonian $H_Q$:\n\n$$ H_Q= \\sum_{i=1}^N \\frac{\\hbar\\Omega}{2} \\sigma_i^x - \\sum_{i=1}^N \\frac{\\hbar \\delta}{2} \\sigma_i^z+\\sum_{j \\lt i}\\frac{C_6}{|\\textbf{r}_i-\\textbf{r}_j|^{6}} n_i n_j. $$\n\nIn the case where our mapping of the atoms is perfect, the last sum replicates exactly the off-diagonal terms of $Q$. In that case, the next step is to prepare the ground-state of $H_Q$ to output the optimal bitstrings.\n\nTo do so we present two different approaches, namely the Quantum Approximation Optimization Algorithm (QAOA) and the Quantum Adiabatic Algorithm (QAA) that have been introduced to prepare ground-states of Hamiltonians.\n### QAOA\nThis algorithm (see [Farhi, et al., 2014](https://arxiv.org/pdf/1411.4028.pdf)) has gained a lot of traction lately as a gate-based quantum algorithm. It has shown promising results in a number of applications and yields decent results for low-depth circuits.\n\nAll atoms are initially in the groundstate $|00\\dots0\\rangle$ of the `ground-rydberg` basis.  We then apply $p$ layers of alternating non-commutative Hamiltonians. The first one, called the mixing Hamiltonian $H_M$, is realized by taking $\\Omega = 1$ rad/\u00b5s, and $\\delta = 0$ rad/\u00b5s in the Hamiltonian equation. The second Hamiltonian $H_Q$ is realized with $\\Omega =0$ rad/\u00b5s and $\\delta = 1.$ rad/\u00b5s. $H_M$ and $H_Q$ are applied turn in turn with parameters $\\tau$ and $t$ respectively. A classical optimizer is then used to estimate the optimal parameters. \n\nInstead of creating a new `Sequence` everytime the quantum loop is called, we are going to create a parametrized `Sequence` and give that to the quantum loop.\nLAYERS = 2\n\n# Parametrized sequence\nseq = Sequence(reg, Chadoq2)\nseq.declare_channel(\"ch0\", \"rydberg_global\")\n\nt_list = seq.declare_variable(\"t_list\", size=LAYERS)\ns_list = seq.declare_variable(\"s_list\", size=LAYERS)\n\nfor t, s in zip(t_list, s_list):\n    pulse_1 = Pulse.ConstantPulse(1000 * t, 1.0, 0.0, 0)\n    pulse_2 = Pulse.ConstantPulse(1000 * s, 0.0, 1.0, 0)\n\n    seq.add(pulse_1, \"ch0\")\n    seq.add(pulse_2, \"ch0\")\n\nseq.measure(\"ground-rydberg\")\nOnce we have the parameters that we want to apply, we use the `.build()` method to assign these values into a `assigned_seq` sequence. It is this sequence which is simulated every time the quantum loop is called.\nExperimentally, we don't have access to the state vector $|\\psi\\rangle$. We therefore make it more realistic by taking samples from the state vector that results from running the simulation with `simul.run()`. This is done with the built-in method `results.sample_final_state()`, in which we add the measurement basis which was declared at the end of the sequence, and the number of samples desired. Currently, the repetition rate of the machine is $5$ Hz.\ndef quantum_loop(parameters):\n    params = np.array(parameters)\n    t_params, s_params = np.reshape(params.astype(int), (2, LAYERS))\n    assigned_seq = seq.build(t_list=t_params, s_list=s_params)\n    simul = QutipEmulator.from_sequence(assigned_seq, sampling_rate=0.01)\n    results = simul.run()\n    count_dict = results.sample_final_state()  # sample from the state vector\n    return count_dict\nnp.random.seed(123)  # ensures reproducibility of the tutorial\nguess = {\n    \"t\": np.random.uniform(8, 10, LAYERS),\n    \"s\": np.random.uniform(1, 3, LAYERS),\n}\nexample_dict = quantum_loop(np.r_[guess[\"t\"], guess[\"s\"]])\nWe can then plot the distribution of the samples, to see the most frequent bitstrings sampled.\ndef plot_distribution(C):\n    C = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n    indexes = [\"01011\", \"00111\"]  # QUBO solutions\n    color_dict = {key: \"r\" if key in indexes else \"g\" for key in C}\n    plt.figure(figsize=(12, 6))\n    plt.xlabel(\"bitstrings\")\n    plt.ylabel(\"counts\")\n    plt.bar(C.keys(), C.values(), width=0.5, color=color_dict.values())\n    plt.xticks(rotation=\"vertical\")\n    plt.show()\nplot_distribution(example_dict)\nThe bitstrings `01011` and `00111` (in red) correspond to the two optimal solutions (calculated at the beginning of the notebook). The goal of QAOA is to choregraph interferences between the basis states, in order to maximize the frequency of the optimal solution states. \n## 3. Optimization \nWe estimate the cost of a sampled state vector by making an average over the samples. This is done by taking the corresponding bitstring ${\\bf z}=(z_1, \\ldots, z_N)$ and calculating\n\n$$\nC({\\bf z}) = {\\bf z}^\\top \\cdot Q \\cdot {\\bf z}\n$$\n\nDetermining the cost of a given bitstring takes polynomial time. The average estimate is then used in the classical loop to optimize the variational parameters $\\tau$ and $t$.\ndef get_cost_colouring(bitstring, Q):\n    z = np.array(list(bitstring), dtype=int)\n    cost = z.T @ Q @ z\n    return cost\n\n\ndef get_cost(counter, Q):\n    cost = sum(counter[key] * get_cost_colouring(key, Q) for key in counter)\n    return cost / sum(counter.values())  # Divide by total samples\nTo perform a minimization loop, we define the following function that will be called at each step by SciPy. `*args` enables to pass the QUBO value, and `params` contains the trial value to score, which changes at each step.\ndef func(param, *args):\n    Q = args[0]\n    C = quantum_loop(param)\n    cost = get_cost(C, Q)\n    return cost\n### QAOA for depth $p = 2$\nWe now use a classical optimizer `minimize` in order to find the best variational parameters. This function takes as arguments `func`, the QUBO $Q$ and an initial point `x0` for the simplex in Nelder-Mead minimization. As the optimizer might get trapped in local minima, we repeat the optimization 20 times and select the parameters that yield the best approximation ratio.\nscores = []\nparams = []\nfor repetition in range(20):\n    guess = {\n        \"t\": np.random.uniform(1, 10, LAYERS),\n        \"s\": np.random.uniform(1, 10, LAYERS),\n    }\n\n    try:\n        res = minimize(\n            func,\n            args=Q,\n            x0=np.r_[guess[\"t\"], guess[\"s\"]],\n            method=\"Nelder-Mead\",\n            tol=1e-5,\n            options={\"maxiter\": 10},\n        )\n        scores.append(res.fun)\n        params.append(res.x)\n    except Exception as e:\n        pass\nWe can now plot the sample that we woud obtain using the optimal variational parameters.\noptimal_count_dict = quantum_loop(params[np.argmin(scores)])\nplot_distribution(optimal_count_dict)\nQAOA is capable of finding good variational parameters $\\tau$ and $t$. Now, sampling from this final state $|\\psi(t_{f})\\rangle$ will return both optimal strings with high probability.\nHowever, using QAOA to solve the problem is not the best idea; it's difficult to yield a >90% quality solution without going to high depths of the QAOA, implying that the growing closed-loop optimization can rapidly become expensive, with no guarantee of convergence. We therefore propose another approach called the Quantum Adiabatic Algorithm (QAA). This fast, reliant and exclusively analog method shows optimal convergence to the solution.\n## Quantum Adiabatic Algorithm\nThe idea behind the adiabatic algorithm (see [Albash, Lidar, 2018](https://arxiv.org/pdf/1611.04471.pdf)) is to slowly evolve the system from an easy-to-prepare groundstate to the groundstate of $H_Q$. If done slowly enough, the system of atoms stays in the instantaneous ground-state.\n\nIn our case, we continuously vary the parameters $\\Omega(t), \\delta(t)$ in time, starting with $\\Omega(0)=0, \\delta(0)<0$ and ending with $\\Omega(0)=0, \\delta>0$. The ground-state of $H(0)$ corresponds to the initial state $|00000\\rangle$ and the ground-state of $H(t_f)$ corresponds to the ground-state of $H_Q$.\nThe Rydberg blockade radius is directly linked to the Rabi frequency $\\Omega$ and is obtained using `Chadoq2.rydberg_blockade_radius()`. In this notebook, $\\Omega$ is initially fixed to a frequency of 1 rad/\u00b5s. We can therefore build the adjacency matrix $A$ of $G$ in the following way:\nTo ensure that we are not exciting the system to states that are too excited, we keep $\\Omega \\in [0, \\Omega_{\\text{max}}]$, and choose $\\Omega_{\\text{max}}$ as the median of the values of Q to ensures that the adiabatic path is efficient.\n# We choose a median value between the min and the max\nOmega = np.median(Q[Q > 0].flatten())\ndelta_0 = -5  # just has to be negative\ndelta_f = -delta_0  # just has to be positive\nT = 4000  # time in ns, we choose a time long enough to ensure the propagation of information in the system\nadiabatic_pulse = Pulse(\n    InterpolatedWaveform(T, [1e-9, Omega, 1e-9]),\n    InterpolatedWaveform(T, [delta_0, 0, delta_f]),\n    0,\n)\nseq = Sequence(reg, Chadoq2)\nseq.declare_channel(\"ising\", \"rydberg_global\")\nseq.add(adiabatic_pulse, \"ising\")\nseq.draw()\nsimul = QutipEmulator.from_sequence(seq)\nresults = simul.run()\nfinal = results.get_final_state()\ncount_dict = results.sample_final_state()\nplot_distribution(count_dict)\nSee how fast and performant this method is! In only a few micro-seconds, we find an excellent solution.\n### How does the time evolution affect the quality of the results?\ncost = []\nfor T in 1000 * np.linspace(1, 10, 10):\n    seq = Sequence(reg, Chadoq2)\n    seq.declare_channel(\"ising\", \"rydberg_global\")\n    adiabatic_pulse = Pulse(\n        InterpolatedWaveform(T, [1e-9, Omega, 1e-9]),\n        InterpolatedWaveform(T, [delta_0, 0, delta_f]),\n        0,\n    )\n    seq.add(adiabatic_pulse, \"ising\")\n    simul = QutipEmulator.from_sequence(seq)\n    results = simul.run()\n    final = results.get_final_state()\n    count_dict = results.sample_final_state()\n    cost.append(get_cost(count_dict, Q) / 3)\nplt.figure(figsize=(12, 6))\nplt.plot(range(1, 11), np.array(cost), \"--o\")\nplt.xlabel(\"total time evolution (\u00b5s)\", fontsize=14)\nplt.ylabel(\"cost\", fontsize=14)\nplt.show()", "params": {}}